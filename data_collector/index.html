<!doctype html>
<html>

<head>
    <meta charset="utf-8" />
    <title>GSL Data Collector</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.0.0/dist/tf.min.js"></script>
    <style>
        video,
        canvas {
            width: 480px;
            height: 360px;
            border: 1px solid #ddd;
        }
    </style>
</head>

<body>
    <h3>GSL Data Collector</h3>
    <label>Class label (e.g., A, B, 1, hello): <input id="label" /></label>
    <button id="startBtn">Start Camera</button>
    <button id="captureBtn">Capture Sample</button>
    <div>
        <video id="video" autoplay muted playsinline></video>
        <canvas id="out"></canvas>
    </div>
    <div>Captured <span id="count">0</span> samples</div>

    <script>
        const video = document.getElementById('video');
        const out = document.getElementById('out');
        const ctx = out.getContext('2d');
        let sampleCount = 0;

        async function startCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
            video.srcObject = stream;
            await video.play();
            out.width = video.videoWidth;
            out.height = video.videoHeight;
        }
        document.getElementById('startBtn').onclick = startCamera;

        const hands = new Hands({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}` });
        hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.6, minTrackingConfidence: 0.6 });
        hands.onResults(onResults);

        const camera = new Camera(video, { onFrame: async () => { await hands.send({ image: video }); }, width: 640, height: 480 });
        document.getElementById('startBtn').addEventListener('click', () => camera.start());

        function onResults(results) {
            ctx.save();
            ctx.clearRect(0, 0, out.width, out.height);
            ctx.drawImage(results.image, 0, 0, out.width, out.height);
            if (results.multiHandLandmarks && results.multiHandLandmarks.length) {
                const lm = results.multiHandLandmarks[0];
                // draw small circles
                ctx.fillStyle = 'red';
                for (let p of lm) {
                    ctx.beginPath(); ctx.arc(p.x * out.width, p.y * out.height, 5, 0, Math.PI * 2); ctx.fill();
                }
                // store last landmarks for capture
                window.lastLandmarks = lm.map(p => [p.x, p.y, p.z]); // normalized
            }
            ctx.restore();
        }

        // Capture button
        document.getElementById('captureBtn').onclick = async () => {
            const label = document.getElementById('label').value.trim();
            if (!label) { alert('Enter label'); return; }
            if (!window.lastLandmarks) { alert('No hand detected'); return; }
            const sample = { label, landmarks: window.lastLandmarks.flat() }; // 63-length
            // POST to server
            await fetch('/upload_sample', {
                method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(sample)
            });
            sampleCount++; document.getElementById('count').innerText = sampleCount;
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</body>

</html>